# Using Prediction in an Application

Almost done. In lab 2 you built a model and in lab 3 you imported that model into a new database, representing a production system. Now we just need to integrate that model with existing applications and processes. It’s worth repeating that this is a critical step. Machine learning models aren’t delivering value until they are being actively used by the company in existing applications and processes.

We will start this lab with some more setup, loading both data and an APEX application, the Alpha Office Customer Service application. Once those are ready we will show you three ways that you could deploy this model.

First, we will integrate it into the Customer Service application. This is something that customer-facing employees would use when interacting with customers. In this case, the customer walks into the office, asks about making a purchase, and the rep can get an immediate answer. By integrating this model with that workflow, we can shorten the process of applying for the new service and improve the customer experience. This is a common situation, where a model can help guide a response to an event as it happens. This would include situations like any customer interaction, recommending products on a web site, processing a financial transaction or responding to a new sensor reading on a piece of equipment.

In the second scenario, we are going to process a large number of customers in batch. Alpha Office has completed an acquisition and inherited some new customers. The marketing department would like to process all those customers at once, perhaps creating a campaign to target those who are suitable. In this lab, we do that using the Customer Service application. It would also be possible to address a use case like this by loading bulk data into the database, running scripts to process them, and making results available through a suitable analytics tool like Oracle Analytics Cloud.

Finally, while APEX applications work well with Oracle Database, many organizations use a distributed development approach. If this is the case, then making a model available via a REST API endpoint is the way to go. We’ll show you how to do that as well.

And when you’ve completed this lab, you are all done. You have setup two autonomous databases, built, trained and deployed a machine learning model. We hope that you can take your new-found skills back to your organization. Are there some business problems that you might be able to help with? Are there existing data sets that colleagues are analyzing where machine learning might help? If you setup a free trial account to do this lab, then you can continue to use the free tier, or your $300 of cloud credits to experiment further. And you can find more information at Oracle.com/machine-learning

## Objectives

In this lab, you will:

- Import data to set up the lab.
- Import an APEX application.
- Review the application to see how you can make predictions on the fly.
- Expose your ml model as a REST end point so any application can use it.

## **Step 1:** Prepare data for the lab in ***ATP***.

- To show how an application would use ml predictions we'll add some customer names to the original credit_scoring_100k data set.  Navigate to the ***ATP*** SQL Developer Web and log in with ml_user (if you are not already logged in from the previous lab).  Then select file upload on the left.

  ![](./images/4/001.png  " ")

- Select the files button, and then the customer_names.csv file in the install directory.

  ![](./images/4/002.png  " ")

- Accept the defaults and hit next.

  ![](./images/4/003.png  " ")

- Change the customer\_id data type to number and change the lengths.

  ![](./images/4/004.png  " ")

- Accept the remaining defaults.

  ![](./images/4/005.png  " ")

- Create a view that combines the names with the credit\_scoring\_100k data set.
```
<copy>create or replace view ml_user.credit_scoring_100k_v as select a.first_name, a.last_name, b.*
from ml_user.customer_names a, credit_scoring_100k b
where a.customer_id(+)= b.customer_id;</copy>
```

  ![](./images/4/006.png  " ")

- Create a new upload\_customers table.  This will be used in the application to show how newly loaded records can be scored on the fly.
```
<copy>create table upload_customers (
customer_id number
, first_name varchar2(100)
, last_name varchar2(100)
, wealth varchar2(4000)
, income number
, customer_dmg_segment varchar2(26)
, customer_value_segment varchar2(26)
, occupation varchar2(26)
, highest_credit_card_limit number
, delinquency_status varchar2(26)
, max_cc_spent_amount number
, max_cc_spent_amount_prev number
, residental_status varchar2(26)
, likely_good_credit_pcnt AS (round((100*(prediction_probability(n1_class_model, 'Good Credit' USING 
    wealth
  , customer_dmg_segment
  , income
  , highest_credit_card_limit
  , residental_status
  , max_cc_spent_amount_prev
  , max_cc_spent_amount
  , occupation
  , delinquency_status
  , customer_value_segment
  , residental_status))),1))
, credit_prediction AS (prediction(n1_class_model USING   
  wealth
  , customer_dmg_segment
  , income
  , highest_credit_card_limit
  , residental_status
  , max_cc_spent_amount_prev
  , max_cc_spent_amount
  , occupation
  , delinquency_status
  , customer_value_segment
  , residental_status))
);</copy>
```

  ![](./images/4/007.png  " ")

## **Step 2:** Import the APEX Application

- Navigate to the ATP APEX application through the ATP Service Console.

  ![](./images/4/008.png  " ")

- Select Development, then APEX.

  ![](./images/4/009.png  " ")

- Enter your admin password.

  ![](./images/4/010.png  " ")

- You will be prompted to create a workspace. 

  ![](./images/4/011.png  " ")

- Select ML\_USER for the workspace user and enter ML\_APPLICATION for the workspace name.

  ![](./images/4/012.png  " ")

  ![](./images/4/013.png  " ")

- Sign out of user admin and log in with workspace ML\_APPLICATION and user ML\_USER.

  ![](./images/4/014.png  " ")

  ![](./images/4/015.png  " ")

   ![](./images/4/016.png  " ")

- You will be prompted to set the new application password for ml\_user.  Make the email proper (not necessarily valid) and accept defaults.

   ![](./images/4/017.png  " ")

   ![](./images/4/018.png  " ")

- Select App Builder.

   ![](./images/4/019.png  " ")

- Select Import

   ![](./images/4/020.png  " ")

- Select choose file, and then select the ***f100.sql*** file in the git repo and then accept the defaults.

   ![](./images/4/021.png  " ")

   ![](./images/4/022.png  " ")

   ![](./images/4/023.png  " ")

   ![](./images/4/024.png  " ")

   ![](./images/4/025.png  " ")

   ![](./images/4/026.png  " ")

   ![](./images/4/027.png  " ")

   ![](./images/4/028.png  " ")

- Log in as ml_user.

   ![](./images/4/029.png  " ")

   ![](./images/4/030.png  " ")

## **Step 3:** Run the application and review on-the-fly prediction/scoring.

- Select Customer Walk-in from the menu.  Select last name, and then first name.  Note the credit score prediction and the probability of that estimate.  These calculations are done as the data is queried.

   ![](./images/4/031.png  " ")

-  Next we will upload new customers and score those as a batch.  Select the Home menu item at the bottom of the page.

   ![](./images/4/032.png  " ")

- Select SQL Workshop.

   ![](./images/4/033.png  " ")

- Select Utilities.

   ![](./images/4/034.png  " ")

- Select Data Workshop.

   ![](./images/4/035.png  " ")

- Select Load Data.

   ![](./images/4/036.png  " ")

- Select the upload_customers.xlsx file.

   ![](./images/4/037.png  " ")

- Load to existing table upload_customers.

   ![](./images/4/038.png  " ")

   ![](./images/4/039.png  " ")

- Return to the Alpha Office application.

   ![](./images/4/040.png  " ")

   ![](./images/4/041.png  " ")

- Run the application

   ![](./images/4/042.png  " ")

- Now review the uploaded customers and note the predictions.

   ![](./images/4/043.png  " ")

- Select Customer Upload Summary.  This provides a summary measure of the uploaded customer number of new good credit versus other credit customers.  This shows there were 40 customers with 100 percent probability of good credit, 83 customers with a 50.7 percent probability of good credit, and 277 customers with a 1.2 percent probability of good credit.

   ![](./images/4/044.png  " ")

- Select Overall Credit Profile.  This provides an overall measure of the credit across the entire 100k credit database.  This scoring of 100k customers with 10 variables takes less than a second.  This shows Alpha Office has 12k customers with a 100 percent probability of good credit, 22k customers with a 50.7 probability of good credit, and 66k customers with a 1.2 percent probability of good credit.

   ![](./images/4/045.png  " ")

## **Step 4:** Expose the ml model as a REST end point so any application can call it.

- Select the Home button at the bottom of the screen.

   ![](./images/4/046.png  " ")

- Select SQL Workshop.

   ![](./images/4/047.png  " ")

- Select RESTFul Services.

   ![](./images/4/048.png  " ")

- Select Module on the left, then Create Module.

   ![](./images/4/049.png  " ")

- Enter the following
    - Module Name - `Predict Credit`
    - Base Path - `/credit/`

  ![](./images/4/050.png  " ")

- Next create a Template.

   ![](./images/4/051.png  " ")

- Enter the following:
    - URI Template: `credit_scoring_100k_v/:wealth/:income`

   ![](./images/4/052.png  " ")

- Next create a handler.  Be sure to select Query one row, and enter the following sql query and select Create Handler.
    - `select prediction(n1_class_model using :wealth as wealth, :income as income) credit_prediction from dual`

   ![](./images/4/053.png  " ")

   ![](./images/4/054.png  " ")

   ![](./images/4/055.png  " ")

- Copy the URL and paste into your browser, and then replace the parameters :wealth and :income with Rich and 20000 respectively.  We are passing the wealth and income variables to the prediction model.  Note these are just two of the many variables we could pass to the model (just add additional ones).  After changing the URL just hit enter.

   ![](./images/4/056.png  " ")

   ![](./images/4/057.png  " ")

This concludes this lab and the workshop.